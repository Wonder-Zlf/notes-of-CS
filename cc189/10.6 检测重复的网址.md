# 10.6 检测重复的网址

要找到重复的网址也就是要记录每个网址，先算一算100亿个网址要占用的多大内存呢？假设每个网址平均长度100个字符，每个字符4字节，那么100亿个网址要占用40000亿个字节也就是约4000GB内存。实际上肯定没有这么大的内存可用，那么后续就要考虑如何拆分计算。

先简化处理，可以得到初步的解决方案。假设现在真有4000GB内存可用，那么统计重复网址就用一个hashSet，出现重复元素就打印出来。



可是没有4000GB内存可用怎么办呢？

解法1：存储至磁盘

若将所有数据存储在一台机器上，可以对数据进行两次扫描。第一次扫描是将网址拆分为4000组，每组就只需要占用1GB内存。简单的做法是将每个网址url存放在txt文件中，其中x=hash(u)%4000。也就是说，我们根据网址的散列值第一次分组，然后第二次扫描就可以用散列表找出重复值。



解法2：多台机器

和解法1操作一样，但是第一次扫描后的网址不需要存储到txt中，而是直接分发到不同机器上然后计算。

并行计算的好处就是耗时少，缺点是你很难获得4000台机器哪怕一半。并且维护4000台机器正常运行也是个工作，你要处理任一机器宕机后的那组数据如何重新计算。



再次强调，和面试官讨论得到具体解决方案，而不是“答题”而已。